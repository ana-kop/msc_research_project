{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing images and videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the large size of the original dataset it was stored on an external drive and all the preprocessing of both images and videos into arrays was done in the local environment; the resulting arrays were then uploaded onto the Google Drive to be used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_dataset(path, number_of_images):\n",
    "    error_counter = 0\n",
    "    counter = 0\n",
    "    dataset = []\n",
    "\n",
    "    for filename in listdir(path):\n",
    "        if counter < number_of_images:\n",
    "            try:\n",
    "                image_path = path + filename\n",
    "                # loading the image and keeping the target size as (224,224,3)\n",
    "                img = image.load_img(image_path, target_size=(224,224,3))\n",
    "                # converting it to array\n",
    "                img = image.img_to_array(img)\n",
    "                # normalizing the pixel value\n",
    "                img = img/255\n",
    "                dataset.append(img)\n",
    "                counter = counter + 1\n",
    "            # check for damaged images\n",
    "            except IOError:\n",
    "                error_counter = error_counter + 1\n",
    "\n",
    "    print('Images added: ' + str(counter))\n",
    "    print('Errors: ' + str(error_counter))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_counterexamples_dataset(dataset, other_folders, n_other):\n",
    "\n",
    "    for i in range(0, len(other_folders)):\n",
    "        path_other = '/Volumes/Drive/IMAGES/' + other_folders[i]\n",
    "\n",
    "        counter = 0\n",
    "        error_counter = 0\n",
    "\n",
    "        for filename in listdir(path_other):\n",
    "            if counter < n_other:\n",
    "\n",
    "                try:\n",
    "                    image_path = path_other + filename\n",
    "                    img = image.load_img(image_path, target_size=(224,224,3))\n",
    "                    img = image.img_to_array(img)\n",
    "                    img = img/255\n",
    "                    dataset.append(img)\n",
    "                    counter = counter + 1\n",
    "\n",
    "                except IOError:\n",
    "                    error_counter = error_counter + 1\n",
    "\n",
    "    print('Images added: ' + str(counter))\n",
    "    print('Errors: ' + str(error_counter))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_names = ['advanced_stop/', 'crossing/', 'cycle_lane/','parking/', 'restricted_route/', 'signal/', 'traffic_calming/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - advanced stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'advanced_stop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 3500\n",
      "Errors: 1\n"
     ]
    }
   ],
   "source": [
    "training_dataset_1 = make_training_dataset('/Volumes/Drive/IMAGES/advanced_stop/', 3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_labels_1 = [class_name for i in range(0, len(training_dataset_1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_folders_1 = [i for i in folder_names if i != (class_name + '/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 583\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "n_other = 583\n",
    "training_dataset_1 = make_training_counterexamples_dataset(training_dataset_1, other_folders_1, n_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_class_name = 'other_a'\n",
    "training_dataset_labels_1 = [counter_class_name for i in range(0, n_other*6)]\n",
    "training_dataset_labels_1.count(counter_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "converting the list to numpy array\n",
    "X = np.array(training_dataset_1)\n",
    "np.save('/Volumes/Drive/NEW/1/X_full_final.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/Volumes/Drive/NEW/1/y_full_final.csv\", \n",
    "           training_dataset_labels_1,\n",
    "           delimiter =\", \",\n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3257"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listdir('/Volumes/Drive/IMAGES/crossing/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "._RWG999514_2.jpg\n",
      "._RWG292165_2.jpg\n",
      "._RWG292619_1.jpg\n",
      "._RWG292618_1.jpg\n",
      "._RWG293101_1.jpg\n",
      "._RWG999328_1.jpg\n",
      "._RWG999449_1.jpg\n",
      "._RWG999925_1.jpg\n",
      "._RWG999844_1.jpg\n"
     ]
    }
   ],
   "source": [
    "for filename in listdir('/Volumes/Drive/IMAGES/crossing/'):\n",
    "    image_path = '/Volumes/Drive/IMAGES/crossing/' + filename\n",
    "    try:\n",
    "        im=image.load_img(image_path)\n",
    "    except IOError:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 3248\n",
      "Errors: 9\n"
     ]
    }
   ],
   "source": [
    "class_name = 'crossing'\n",
    "training_dataset_2 = make_training_dataset('/Volumes/Drive/IMAGES/crossing/', 3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_labels_2 = [class_name for i in range(0, len(training_dataset_2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_folders_2 = [i for i in folder_names if i != (class_name + '/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 541\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "n_other = 541\n",
    "training_dataset_2 = make_training_counterexamples_dataset(training_dataset_2, other_folders_2, n_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3246"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_class_name = 'other_c'\n",
    "training_dataset_labels_2 = [counter_class_name for i in range(0, n_other*6)]\n",
    "training_dataset_labels_2.count(counter_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(training_dataset_2)\n",
    "np.save('/Volumes/Drive/NEW/2/X_full_final.npy', X)\n",
    "\n",
    "np.savetxt(\"/Volumes/Drive/NEW/2/y_full_final.csv\", \n",
    "           training_dataset_labels_2,\n",
    "           delimiter =\", \",\n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Cycle lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 3500\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "class_name = 'cycle_lane'\n",
    "training_dataset_3 = make_training_dataset('/Volumes/Drive/IMAGES/cycle_lane/', 3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_labels_3 = [class_name for i in range(0, len(training_dataset_3))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 583\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "other_folders_3 = [i for i in folder_names if i != (class_name + '/')]\n",
    "n_other = 583\n",
    "training_dataset_3 = make_training_counterexamples_dataset(training_dataset_3, other_folders_3, n_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_class_name = 'other_l'\n",
    "training_dataset_labels_3 = [counter_class_name for i in range(0, n_other*6)]\n",
    "training_dataset_labels_3.count(counter_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(training_dataset_3)\n",
    "np.save('/Volumes/Drive/NEW/3/X_full_final.npy', X)\n",
    "\n",
    "np.savetxt(\"/Volumes/Drive/NEW/3/y_full_final.csv\", \n",
    "           training_dataset_labels_3,\n",
    "           delimiter =\", \",\n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 3500\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "class_name = 'parking'\n",
    "training_dataset_4 = make_training_dataset('/Volumes/Drive/IMAGES/parking/', 3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_labels_4 = [class_name for i in range(0, len(training_dataset_4))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 583\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "other_folders_4 = [i for i in folder_names if i != (class_name + '/')]\n",
    "n_other = 583\n",
    "training_dataset_4 = make_training_counterexamples_dataset(training_dataset_4, other_folders_4, n_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_class_name = 'other_p'\n",
    "training_dataset_labels_4 = [counter_class_name for i in range(0, n_other*6)]\n",
    "training_dataset_labels_4.count(counter_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(training_dataset_4)\n",
    "np.save('/Volumes/Drive/NEW/4/X_full_final.npy', X)\n",
    "\n",
    "np.savetxt(\"/Volumes/Drive/NEW/4/y_full_final.csv\", \n",
    "           training_dataset_labels_4,\n",
    "           delimiter =\", \",\n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Restricted route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 2550\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "class_name = 'restricted_route'\n",
    "training_dataset_5 = make_training_dataset('/Volumes/Drive/IMAGES/restricted_route/', 2550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_labels_5 = [class_name for i in range(0, len(training_dataset_5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 425\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "other_folders_5 = [i for i in folder_names if i != (class_name + '/')]\n",
    "n_other = 425\n",
    "training_dataset_5 = make_training_counterexamples_dataset(training_dataset_5, other_folders_5, n_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2550"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_class_name = 'other_r'\n",
    "training_dataset_labels_5 = [counter_class_name for i in range(0, n_other*6)]\n",
    "training_dataset_labels_5.count(counter_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(training_dataset_5)\n",
    "np.save('/Volumes/Drive/NEW/5/X_full_final_e.npy', X)\n",
    "\n",
    "np.savetxt(\"/Volumes/Drive/NEW/5/y_full_final_e.csv\", \n",
    "           training_dataset_labels_5,\n",
    "           delimiter =\", \",\n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 809\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "class_name = 'signal'\n",
    "training_dataset_6 = make_training_dataset('/Volumes/Drive/IMAGES/signal/', 809)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_labels_6 = [class_name for i in range(0, len(training_dataset_6))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 135\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "other_folders_6 = [i for i in folder_names if i != (class_name + '/')]\n",
    "n_other = 135\n",
    "training_dataset_6 = make_training_counterexamples_dataset(training_dataset_6, other_folders_6, n_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_class_name = 'other_s'\n",
    "training_dataset_labels_6 = [counter_class_name for i in range(0, n_other*6)]\n",
    "training_dataset_labels_6.count(counter_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(training_dataset_6)\n",
    "np.save('/Volumes/Drive/NEW/6/X_full_final.npy', X)\n",
    "\n",
    "np.savetxt(\"/Volumes/Drive/NEW/6/y_full_final.csv\", \n",
    "           training_dataset_labels_6,\n",
    "           delimiter =\", \",\n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - traffic calming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 3500\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "class_name = 'traffic_calming'\n",
    "training_dataset_7 = make_training_dataset('/Volumes/Drive/IMAGES/traffic_calming/', 3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset_labels_7 = [class_name for i in range(0, len(training_dataset_7))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images added: 583\n",
      "Errors: 0\n"
     ]
    }
   ],
   "source": [
    "other_folders_7 = [i for i in folder_names if i != (class_name + '/')]\n",
    "n_other = 583\n",
    "training_dataset_7 = make_training_counterexamples_dataset(training_dataset_7, other_folders_7, n_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_class_name = 'other_t'\n",
    "training_dataset_labels_7 = [counter_class_name for i in range(0, n_other*6)]\n",
    "training_dataset_labels_7.count(counter_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(training_dataset_7)\n",
    "np.save('/Volumes/Drive/NEW/7/X_full_final.npy', X)\n",
    "\n",
    "np.savetxt(\"/Volumes/Drive/NEW/7/y_full_final.csv\", \n",
    "           training_dataset_labels_7,\n",
    "           delimiter =\", \",\n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_extra(path, frame_rate):\n",
    "    \n",
    "    counter = 0\n",
    "    error_counter = 0\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        file_path = path + filename\n",
    "        try:\n",
    "            if counter%frame_rate == 0:\n",
    "                counter = counter + 1\n",
    "            else:\n",
    "                os.remove(file_path)\n",
    "                counter = counter + 1\n",
    "\n",
    "        except IOError:\n",
    "                error_counter = error_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe with video names\n",
    "test_video = pd.DataFrame(columns=['video_name'])\n",
    "for i in range(1,12):\n",
    "    name = 'video_' + str(i) + '.MOV'\n",
    "    test_video = test_video.append({'video_name' : name}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/Users/ak/Desktop/videos/video_10.MOV')\n",
    "count = 0\n",
    "fps = round(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "success,image = cap.read()\n",
    "\n",
    "while success:\n",
    "    filename = \"/Volumes/Drive/video_10/video_10_frame%d.jpg\" % count\n",
    "    cv2.imwrite(filename, image)\n",
    "    success,image = cap.read()\n",
    "    count += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "delete_extra('/Volumes/Drive/video_10/', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
